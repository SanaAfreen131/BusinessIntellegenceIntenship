{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49aa1e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: haystack-ai==2.19 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (2.19.0)\n",
      "Requirement already satisfied: docstring-parser in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (0.17.0)\n",
      "Requirement already satisfied: filetype in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (1.2.0)\n",
      "Requirement already satisfied: haystack-experimental in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (0.14.3)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (4.23.0)\n",
      "Requirement already satisfied: lazy-imports in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (10.5.0)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (3.4.2)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.13/site-packages (from haystack-ai==2.19) (2.2.6)\n",
      "Requirement already satisfied: openai>=1.99.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (2.8.1)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (7.0.1)\n",
      "Requirement already satisfied: pydantic in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (2.12.4)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python3.13/site-packages (from haystack-ai==2.19) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (9.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai==2.19) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai==2.19) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->haystack-ai==2.19) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->haystack-ai==2.19) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->haystack-ai==2.19) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests->haystack-ai==2.19) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.13/site-packages (from requests->haystack-ai==2.19) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests->haystack-ai==2.19) (2.3.0)\n",
      "Requirement already satisfied: rich in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-experimental->haystack-ai==2.19) (14.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->haystack-ai==2.19) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/lib64/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (0.25.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai==2.19) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai==2.19) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai==2.19) (0.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai==2.19) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai==2.19) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->haystack-experimental->haystack-ai==2.19) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: colorama in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (0.4.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ollama-haystack in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (5.3.0)\n",
      "Requirement already satisfied: haystack-ai>=2.19.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from ollama-haystack) (2.19.0)\n",
      "Requirement already satisfied: ollama>=0.5.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from ollama-haystack) (0.6.1)\n",
      "Requirement already satisfied: pydantic in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from ollama-haystack) (2.12.4)\n",
      "Requirement already satisfied: docstring-parser in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (0.17.0)\n",
      "Requirement already satisfied: filetype in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (1.2.0)\n",
      "Requirement already satisfied: haystack-experimental in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (0.14.3)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (4.23.0)\n",
      "Requirement already satisfied: lazy-imports in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (10.5.0)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (3.4.2)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.2.6)\n",
      "Requirement already satisfied: openai>=1.99.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.8.1)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (7.0.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (9.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (4.15.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /usr/lib/python3.13/site-packages (from ollama>=0.5.0->ollama-haystack) (0.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->ollama-haystack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->ollama-haystack) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->ollama-haystack) (0.4.2)\n",
      "Requirement already satisfied: anyio in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (4.8.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama>=0.5.0->ollama-haystack) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai>=2.19.0->ollama-haystack) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai>=2.19.0->ollama-haystack) (0.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai>=2.19.0->ollama-haystack) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai>=2.19.0->ollama-haystack) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests->haystack-ai>=2.19.0->ollama-haystack) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests->haystack-ai>=2.19.0->ollama-haystack) (2.3.0)\n",
      "Requirement already satisfied: rich in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (14.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->haystack-ai>=2.19.0->ollama-haystack) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/lib64/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (0.25.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers>=4.1.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from sentence-transformers>=4.1.0) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.13/site-packages (from sentence-transformers>=4.1.0) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from sentence-transformers>=4.1.0) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from sentence-transformers>=4.1.0) (1.7.2)\n",
      "Requirement already satisfied: scipy in /usr/lib64/python3.13/site-packages (from sentence-transformers>=4.1.0) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from sentence-transformers>=4.1.0) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib64/python3.13/site-packages (from sentence-transformers>=4.1.0) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from sentence-transformers>=4.1.0) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib64/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (74.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=4.1.0) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib64/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=4.1.0) (2.2.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/lib64/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=4.1.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=4.1.0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=4.1.0) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from scikit-learn->sentence-transformers>=4.1.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from scikit-learn->sentence-transformers>=4.1.0) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=4.1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=4.1.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=4.1.0) (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install haystack-ai==2.19\n",
    "! pip install colorama\n",
    "! pip install ollama-haystack\n",
    "! pip install \"sentence-transformers>=4.1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f8f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from datetime import date\n",
    "import json\n",
    "import random\n",
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional, List\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "from haystack.dataclasses import ChatMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6074ab9",
   "metadata": {},
   "source": [
    "<font size=\"6\">Exercise 1b defing datastructure for the extraction of tasks</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1021c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "class Task(BaseModel):\n",
    "    name: str\n",
    "\n",
    "class TasksData(BaseModel):\n",
    "    tasks: List[Task]\n",
    "\n",
    "json_schema = TasksData.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674bb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_schema = TasksData.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35c5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the component input parameters\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    # Define the component output\n",
    "    @component.output_types(valid_replies=List[ChatMessage], invalid_replies=List[ChatMessage], error_message=Optional[str])\n",
    "    def run(self, replies: List[ChatMessage]):\n",
    "\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        ## Try to parse the LLM's reply ##\n",
    "        # If the LLM's reply is a valid object, return `\"valid_replies\"`\n",
    "        try:\n",
    "            output_dict = json.loads(replies[0].text)\n",
    "            self.pydantic_model.model_validate(output_dict)\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": replies}\n",
    "\n",
    "        # If the LLM's reply is corrupted or not valid, return \"invalid_replies\" and the \"error_message\" for LLM to try again\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc624d8",
   "metadata": {},
   "source": [
    " <font size=\"6\">Exercise 1c The component ‚ÄúOutputValidator‚Äù by using our datastructure-template as a variable</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbad105",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = OutputValidator(pydantic_model=TasksData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc112d",
   "metadata": {},
   "source": [
    " <font size=\"6\">Exercise 1d prompt to instruct an LLM to extract task names from a BPMN description</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c5c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import ChatPromptBuilder\n",
    "\n",
    "prompt_template = [\n",
    "    ChatMessage.from_user(\n",
    "        \"\"\"\n",
    "Extract all *task names* from the following BPMN description:\n",
    "\n",
    "{{bpmn_description}}\n",
    "\n",
    "Return ONLY JSON in the following format:\n",
    "\n",
    "{\n",
    "  \"tasks\": [\n",
    "    {\"name\": \"task name 1\"},\n",
    "    {\"name\": \"task name 2\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "RULES:\n",
    "- Extract only task NAMES.\n",
    "- Output must be valid JSON.\n",
    "- Do NOT include explanations.\n",
    "- Do NOT include code fences.\n",
    "- Do NOT include the schema.\n",
    "\n",
    "{% if invalid_replies and error_message %}\n",
    "Your previous output was invalid:\n",
    "\n",
    "{{invalid_replies}}\n",
    "\n",
    "Error:\n",
    "\n",
    "{{error_message}}\n",
    "\n",
    "Please correct your answer and return valid JSON.\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "required_vars = [\"bpmn_description\"]\n",
    "\n",
    "prompt_builder = ChatPromptBuilder(\n",
    "    template=prompt_template,\n",
    "    required_variables=required_vars\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213e87d",
   "metadata": {},
   "source": [
    " <font size=\"6\">Excersie 1e generator with the OllamaChatGenerator Llama3.1</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from haystack_integrations.components.generators.ollama import  OllamaChatGenerator\n",
    "\n",
    "chat_generator = OllamaChatGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=30*60,  \n",
    "    generation_kwargs={\n",
    "        \"num_ctx\": 4096,\n",
    "        \"temperature\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1549e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f127430d400>\n",
       "üöÖ Components\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OllamaChatGenerator\n",
       "  - validator: OutputValidator\n",
       "üõ§Ô∏è Connections\n",
       "  - prompt_builder.prompt -> llm.messages (list[ChatMessage])\n",
       "  - llm.replies -> validator.replies (List[ChatMessage])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "pipeline = Pipeline(max_runs_per_component=5)\n",
    "\n",
    "pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipeline.add_component(\"llm\", chat_generator)\n",
    "pipeline.add_component(\"validator\", validator)\n",
    "\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
    "pipeline.connect(\"llm.replies\", \"validator.replies\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17898d5",
   "metadata": {},
   "source": [
    " <font size=\"6\">Excersie 1f Running the pipeline for 3 different descriptive texts</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34906361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================== BPMN RUN 1 ======================\n",
      "\n",
      "\u001b[32mOutputValidator at Iteration 1: Valid JSON from LLM - No need for looping: ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='{\\n  \"tasks\": [\\n    {\"name\": \"Validate order\"},\\n    {\"name\": \"Pick items from warehouse\"},\\n    {\"name\": \"Pack and ship items\"},\\n    {\"name\": \"Deliver package to customer\"}\\n  ]\\n}')], _name=None, _meta={'model': 'llama3.1:8b', 'done': True, 'total_duration': 16527908878, 'load_duration': 1201863360, 'prompt_eval_duration': 7082000000, 'eval_duration': 8242000000, 'logprobs': None, 'finish_reason': 'stop', 'completion_start_time': '2025-12-02T21:49:20.494050847Z', 'usage': {'completion_tokens': 49, 'prompt_tokens': 145, 'total_tokens': 194}})\n",
      "‚úÖ Valid JSON Output:\n",
      " {\n",
      "  \"tasks\": [\n",
      "    {\"name\": \"Validate order\"},\n",
      "    {\"name\": \"Pick items from warehouse\"},\n",
      "    {\"name\": \"Pack and ship items\"},\n",
      "    {\"name\": \"Deliver package to customer\"}\n",
      "  ]\n",
      "}\n",
      "\n",
      "Parsed tasks: ['Validate order', 'Pick items from warehouse', 'Pack and ship items', 'Deliver package to customer']\n",
      "\n",
      "====================== BPMN RUN 2 ======================\n",
      "\n",
      "\u001b[32mOutputValidator at Iteration 2: Valid JSON from LLM - No need for looping: ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='{\\n  \"tasks\": [\\n    {\"name\": \"Log in\"},\\n    {\"name\": \"Check credentials\"},\\n    {\"name\": \"Display dashboard\"},\\n    {\"name\": \"Upload files\"},\\n    {\"name\": \"Log out\"}\\n  ]\\n}')], _name=None, _meta={'model': 'llama3.1:8b', 'done': True, 'total_duration': 14070965776, 'load_duration': 18308388, 'prompt_eval_duration': 5720000000, 'eval_duration': 8331000000, 'logprobs': None, 'finish_reason': 'stop', 'completion_start_time': '2025-12-02T21:49:34.568248151Z', 'usage': {'completion_tokens': 50, 'prompt_tokens': 138, 'total_tokens': 188}})\n",
      "‚úÖ Valid JSON Output:\n",
      " {\n",
      "  \"tasks\": [\n",
      "    {\"name\": \"Log in\"},\n",
      "    {\"name\": \"Check credentials\"},\n",
      "    {\"name\": \"Display dashboard\"},\n",
      "    {\"name\": \"Upload files\"},\n",
      "    {\"name\": \"Log out\"}\n",
      "  ]\n",
      "}\n",
      "\n",
      "Parsed tasks: ['Log in', 'Check credentials', 'Display dashboard', 'Upload files', 'Log out']\n",
      "\n",
      "====================== BPMN RUN 3 ======================\n",
      "\n",
      "\u001b[32mOutputValidator at Iteration 3: Valid JSON from LLM - No need for looping: ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='{\\n  \"tasks\": [\\n    {\"name\": \"Fill out a contact form\"},\\n    {\"name\": \"Store request\"},\\n    {\"name\": \"Review request\"},\\n    {\"name\": \"Send response email\"},\\n    {\"name\": \"Close ticket\"}\\n  ]\\n}')], _name=None, _meta={'model': 'llama3.1:8b', 'done': True, 'total_duration': 15137768708, 'load_duration': 18373294, 'prompt_eval_duration': 6242000000, 'eval_duration': 8875000000, 'logprobs': None, 'finish_reason': 'stop', 'completion_start_time': '2025-12-02T21:49:49.708654952Z', 'usage': {'completion_tokens': 54, 'prompt_tokens': 135, 'total_tokens': 189}})\n",
      "‚úÖ Valid JSON Output:\n",
      " {\n",
      "  \"tasks\": [\n",
      "    {\"name\": \"Fill out a contact form\"},\n",
      "    {\"name\": \"Store request\"},\n",
      "    {\"name\": \"Review request\"},\n",
      "    {\"name\": \"Send response email\"},\n",
      "    {\"name\": \"Close ticket\"}\n",
      "  ]\n",
      "}\n",
      "\n",
      "Parsed tasks: ['Fill out a contact form', 'Store request', 'Review request', 'Send response email', 'Close ticket']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bpmn_inputs = [\n",
    "    \"\"\"\n",
    "    The process starts when a customer submits an order.\n",
    "    Then the system validates the order.\n",
    "    Next, the warehouse picks the items.\n",
    "    After that, the items are packed and shipped.\n",
    "    Finally, the customer receives the package.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    A user logs into the platform.\n",
    "    The system checks credentials.\n",
    "    If valid, a dashboard is displayed.\n",
    "    The user can then upload files.\n",
    "    The process ends when the user logs out.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    A visitor fills out a contact form.\n",
    "    The system stores the request.\n",
    "    An agent reviews the request.\n",
    "    The agent sends a response email.\n",
    "    The ticket is then closed.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "for i, bpmn_description in enumerate(bpmn_inputs, start=1):\n",
    "    print(f\"\\n====================== BPMN RUN {i} ======================\\n\")\n",
    "\n",
    "    result = pipeline.run({\n",
    "        \"prompt_builder\": {\n",
    "            \"bpmn_description\": bpmn_description\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Extract valid reply\n",
    "    if \"validator\" in result and result[\"validator\"].get(\"valid_replies\"):\n",
    "        valid_output = result[\"validator\"][\"valid_replies\"][0].text\n",
    "        print(\"‚úÖ Valid JSON Output:\\n\", valid_output)\n",
    "\n",
    "        parsed = TasksData.model_validate_json(valid_output)\n",
    "        print(\"\\nParsed tasks:\", [t.name for t in parsed.tasks])\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùå No valid reply found for this BPMN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b42f35",
   "metadata": {},
   "source": [
    "Order Fulfillment Process\n",
    "The model was able to identify 4 tasks out of 5¬†\n",
    "Precision = 1 Recall = 0.8\n",
    "User Login\n",
    "The model was able to identify 5 tasks out of 5\n",
    "Precision = 1 Recall = 1\n",
    "Customer support\n",
    "The model was able to identify 5¬†tasks¬†out of 5\n",
    "Precision = 1 Recall = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da7284",
   "metadata": {},
   "source": [
    "<font size=\"6\">Exercise 2a(1) Chat PromptBuilder that receives a query containing a BPMN model and its textual description</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import ChatPromptBuilder\n",
    "\n",
    "second_prompt_template = ChatPromptBuilder(\n",
    "    template=[\n",
    "        ChatMessage.from_user(\n",
    "            \"\"\"\n",
    "You are given a BPMN model and its textual description.\n",
    "Your task is to annotate the text by wrapping each BPMN element with its corresponding tag.\n",
    "For example:\n",
    "  - A task should be wrapped as: <bpmn:task>Task Name</bpmn:task>\n",
    "  - A start event as: <bpmn:startEvent>Event Description</bpmn:startEvent>\n",
    "  - A gateway as: <bpmn:exclusiveGateway>Decision Point</bpmn:exclusiveGateway>\n",
    "\n",
    "Here is the BPMN model: {{bpmn_model}}\n",
    "Here is the text: {{text_description}}\n",
    "Annotate the text below:\n",
    "\n",
    "\"\"\"\n",
    "        )\n",
    "    ],\n",
    "    required_variables=[\"bpmn_model\",\"text_description\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a83d00",
   "metadata": {},
   "source": [
    "<font size=\"6\">Exercise 2a(2) A generator that works with the BPMN model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.generators.ollama import  OllamaChatGenerator\n",
    "\n",
    "second_chat_generator = OllamaChatGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=30 * 60,\n",
    "    generation_kwargs={\n",
    "        \"num_ctx\": 4096,\n",
    "        \"temperature\": 0.7, \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e78208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f036f9aa3c0>\n",
       "üöÖ Components\n",
       "  - prompt: ChatPromptBuilder\n",
       "  - llm: OllamaChatGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - prompt.prompt -> llm.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "second_pipeline = Pipeline()\n",
    "second_pipeline.add_component(\"prompt\", second_prompt_template)\n",
    "second_pipeline.add_component(\"llm\", second_chat_generator)\n",
    "second_pipeline.connect(\"prompt.prompt\", \"llm.messages\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6820d0",
   "metadata": {},
   "source": [
    "<font size=\"6\">Exercise 2b Running pipeline for 3 different BPMN-text pairs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c77b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "‚úÖ Annotated Output:\n",
      "\n",
      "Here is the annotated text:\n",
      "\n",
      "<bpmn:startEvent>Passenger presents their boarding pass</bpmn:startEvent>\n",
      "at the <bpmn:startEvent>Start Event</bpmn:startEvent>.\n",
      "After this, the passenger proceeds to the <bpmn:task>Security Check</bpmn:task>,\n",
      "where security personnel conduct the initial screening.\n",
      "Once the check is completed, an <bpmn:exclusiveGateway>Exclusive Gateway</bpmn:exclusiveGateway>\n",
      "evaluates whether the passenger appears suspicious.\n",
      "\n",
      "If the passenger is not suspicious, the flow continues normally to the <bpmn:task>Manual Control</bpmn:task>,\n",
      "where additional checks are carried out. When manual control is finished,\n",
      "the process loops back to the <bpmn:exclusiveGateway>Exclusive Gateway</bpmn:exclusiveGateway>\n",
      "to determine whether the passenger's destination lies within the Schengen area.\n",
      "\n",
      "If the destination is within the Schengen zone, the passenger moves on to <bpmn:task>Passport Control</bpmn:task>,\n",
      "where immigration officers verify their passport. \n",
      "If the destination is outside the Schengen area, the passenger skips <bpmn:task>Passport Control</bpmn:task>\n",
      "entirely and proceeds straight to the gate.\n",
      "The process concludes with the passenger arriving at the gate,\n",
      "represented by the <bpmn:endEvent>End Event</bpmn:endEvent>.\n"
     ]
    }
   ],
   "source": [
    "TEXT_FILE = \"Passenger Security.txt\"\n",
    "BPMN_FILE = \"Passanger_security.bpmn\"  \n",
    "\n",
    "with open(TEXT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_description = f.read().strip()\n",
    "with open(BPMN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    bpmn_model = f.read().strip()\n",
    "\n",
    "result = second_pipeline.run({\n",
    "    \"prompt\": {\n",
    "        \"text_description\": text_description,\n",
    "        \"bpmn_model\": bpmn_model\n",
    "    }\n",
    "})\n",
    "\n",
    "annotated = result[\"llm\"][\"replies\"][0].text.strip()\n",
    "print(Fore.GREEN + \"\\n‚úÖ Annotated Output:\\n\")\n",
    "print(annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ea72c",
   "metadata": {},
   "source": [
    "Passenger Security\n",
    "The model were able to annotate 0 events out of 2, 4 tasks out of 7 and 2 gateways out of 4\n",
    "Precision =0.85 Recall = 0.428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9ecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "‚úÖ Annotated Output:\n",
      "\n",
      "Here is the annotated text:\n",
      "\n",
      "Managing Excess Carry-On Baggage Due to High Occupancy \n",
      "\n",
      "The <bpmn:process> begins when the passenger checks in for the flight. After check-in, the <bpmn:task> \"Assess Flight Occupancy\" evaluates the flight‚Äôs occupancy level.\n",
      "An <bpmn:exclusiveGateway> then determines whether the occupancy is high. If it is high, the process continues with the team enhancing baggage control by executing the <bpmn:task> \"Enhance baggage control\", \n",
      "after which passengers are notified about strict carry-on enforcement through the execution of the <bpmn:task> \"Notify passengers of strict carry-on enforcement\". If the occupancy is not high, the team instead applies the standard carry-on procedures by executing the <bpmn:task> \"apply standard carry-on procedures\".\n",
      "Following this, the gate staff receive a notification regarding the flight situation through the execution of the <bpmn:task> \"Receive notification\", and the passenger eventually arrives at the gate.\n",
      "Another <bpmn:exclusiveGateway> then checks whether the passenger is ready for boarding. If the passenger is ready, they are allowed to board the flight by executing the <bpmn:task> \"Allow passenger for boarding\". If the passenger is not ready, \n",
      "the process moves to another <bpmn:exclusiveGateway> that verifies the passenger‚Äôs carry-on items at gate level through the execution of the <bpmn:task> \"Tag item and load it into the aircraft hold\".\n",
      "If the carry-on passes verification, the passenger proceeds to boarding; if it does not, the process continues with the <bpmn:startEvent> being triggered.\n",
      "The process concludes once the passenger boards the flight and \n",
      "the <bpmn:endEvent> is triggered.\n"
     ]
    }
   ],
   "source": [
    "TEXT_FILE_2 = \"Excese_bagage.txt\"\n",
    "BPMN_FILE_2 = \"Excese_bagage.bpmn\"  \n",
    "\n",
    "with open(TEXT_FILE_2, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_description = f.read().strip()\n",
    "\n",
    "with open(BPMN_FILE_2, \"r\", encoding=\"utf-8\") as f:\n",
    "    bpmn_model = f.read().strip()\n",
    "\n",
    "result = second_pipeline.run({\n",
    "    \"prompt\": {\n",
    "        \"text_description\": text_description,\n",
    "        \"bpmn_model\": bpmn_model\n",
    "    }\n",
    "})\n",
    "\n",
    "annotated = result[\"llm\"][\"replies\"][0].text.strip()\n",
    "print(Fore.GREEN + \"\\n‚úÖ Annotated Output:\\n\")\n",
    "print(annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb81121",
   "metadata": {},
   "source": [
    "Execs Baggage¬†\n",
    "The model were able to annotate 1 events out of 2,¬† 8 tasks out of 12 and 2 gateways out of 3\n",
    "Precision = 0.85¬† Recall = 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "‚úÖ Annotated Output:\n",
      "\n",
      "Here is the annotated text:\n",
      "\n",
      "The process begins with the start event <bpmn:startEvent>Passenger Arrives at Destination Without Baggage</bpmn:startEvent>, \n",
      "after which the passenger performs the task <bpmn:task>Report Delayed Baggage</bpmn:task>. The Baggage Service Office then executes <bpmn:task>Receive report</bpmn:task> followed by <bpmn:task>Initiate Baggage Tracing</bpmn:task>. \n",
      "The Baggage Logistics System carries out <bpmn:task>traces baggage across airlines</bpmn:task>, \n",
      "after which the process reaches the exclusive gateway <bpmn:exclusiveGateway>Is Baggage Located Within 24 Hours?</bpmn:exclusiveGateway>&mdash;if yes, \n",
      "it proceeds to <bpmn:task>Proceed to delivery</bpmn:task>; if no, it performs <bpmn:task>Continue tracing</bpmn:task> and loops back to reassess. \n",
      "Once the baggage is ready for delivery, the Baggage Service Office performs <bpmn:task>activate interim support</bpmn:task>, \n",
      "which is followed by <bpmn:task>Receive interim support</bpmn:task>. Then, the task <bpmn:task>Deliver Baggage to Passenger</bpmn:task> is executed, \n",
      "leading to the second decision gateway <bpmn:exclusiveGateway>Is Baggage Found Within 21 Days?</bpmn:exclusiveGateway>&mdash;if yes, the process performs <bpmn:task>close case</bpmn:task>; if no, it executes <bpmn:task>Presumed Lost</bpmn:task>. \n",
      "Both paths converge before the final task <bpmn:task>Passenger confirms Delivery</bpmn:task>, which concludes the process.\n",
      " All elements&mdash;including the start event <bpmn:startEvent>Passenger Arrives at Destination Without Baggage</bpmn:startEvent>, \n",
      " all listed tasks, and both gateways (<bpmn:exclusiveGateway>Is Baggage Located Within 24 Hours?</bpmn:exclusiveGateway> and <bpmn:exclusiveGateway>Is Baggage Found Within 21 Days?</bpmn:exclusiveGateway>) \n",
      " are integral parts of this end-to-end baggage resolution workflow.\n"
     ]
    }
   ],
   "source": [
    "TEXT_FILE_3 = \"Delayed Baggage.txt\"\n",
    "BPMN_FILE_3 = \"Delayed_bagage.bpmn\"  \n",
    "\n",
    "with open(TEXT_FILE_3, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_description = f.read().strip()\n",
    "\n",
    "with open(BPMN_FILE_3, \"r\", encoding=\"utf-8\") as f:\n",
    "    bpmn_model = f.read().strip()\n",
    "\n",
    "result = second_pipeline.run({\n",
    "    \"prompt\": {\n",
    "        \"text_description\": text_description,\n",
    "        \"bpmn_model\": bpmn_model\n",
    "    }\n",
    "})\n",
    "\n",
    "annotated = result[\"llm\"][\"replies\"][0].text.strip()\n",
    "print(Fore.GREEN + \"\\n‚úÖ Annotated Output:\\n\")\n",
    "print(annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66af0b",
   "metadata": {},
   "source": [
    "Delayed Baggage\n",
    "The model were able to annotate 0 events out of 2 , 13 tasks out of 13¬† and 2 gateways out of 4¬†\n",
    "Precision = 1 Recall = 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add95503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack import Document\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1122f",
   "metadata": {},
   "source": [
    " <font size=\"6\">Exercise 3 Intitionaliazing document store containing BPMN-text pairs</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c09bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded and embedded 4 documents into the document store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "doc_embedder.warm_up()\n",
    "\n",
    "file_paths = [\n",
    "    \"Exces_bagagePair.txt\",\n",
    "    \"Passenger_ArrivalPair.txt\",\n",
    "    \"Passenger_Securitypair.txt\",\n",
    "    \"Delayed_BaggagePair.txt\"\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().strip()\n",
    "       \n",
    "        doc = Document(content=content, meta={\"source\": file_path})\n",
    "        docs.append(doc)\n",
    "       \n",
    "embedded_docs = doc_embedder.run(docs)\n",
    "\n",
    "document_store.write_documents(embedded_docs[\"documents\"])\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded and embedded {len(docs)} documents into the document store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95cbe29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store)\n",
    "text_embedder = SentenceTransformersTextEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d375cd8",
   "metadata": {},
   "source": [
    "<font size=\"6\">Exercise 3(1) ChatPromptBuilder that receives a query containing a BPMN model and an example BPMN-text pair</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32529538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import ChatPromptBuilder\n",
    "\n",
    "Third_prompt_template = ChatPromptBuilder(\n",
    "    template=[\n",
    "        ChatMessage.from_user(\n",
    "            \"\"\"\n",
    "You are an expert in BPMN. Your task is to generate a fluent natural-language description of a given BPMN model and annotate every process element using BPMN tags.\n",
    "\n",
    "First, study this example that shows a BPMN model and its corresponding plain-language description:\n",
    "\n",
    "{{example_pair}}\n",
    "\n",
    "Now, generate a new annotated description for the following BPMN model:\n",
    "\n",
    "{{new_bpmn}}\n",
    "\n",
    "Instructions:\n",
    "- Write a clear, step-by-step description of the process.\n",
    "- Annotate every element using the correct tag:\n",
    "  ‚Ä¢ Task ‚Üí <bpmn:task>Exact Task Name</bpmn:task>\n",
    "  ‚Ä¢ Start Event ‚Üí <bpmn:startEvent>Exact Event Text</bpmn:startEvent>\n",
    "  ‚Ä¢ End Event ‚Üí <bpmn:endEvent>Exact Event Text</bpmn:endEvent>\n",
    "  ‚Ä¢ Exclusive Gateway ‚Üí <bpmn:exclusiveGateway>Exact Gateway Question</bpmn:exclusiveGateway>\n",
    "- Use ONLY the exact names that appear in the BPMN model.\n",
    "- Do NOT add any extra text, explanations, or formatting‚Äîonly return the annotated description.\n",
    "\n",
    "Generated Annotated Description:\n",
    "\n",
    "\"\"\"\n",
    "        )\n",
    "    ],\n",
    "    required_variables=[\"example_pair\",\"new_bpmn\"]  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06035e3a",
   "metadata": {},
   "source": [
    " <font size=\"6\">Exercise 3 A matching generator</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.generators.ollama import  OllamaChatGenerator\n",
    "third_chat_generator = OllamaChatGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=30 * 60,\n",
    "    generation_kwargs={\n",
    "        \"num_ctx\": 4096,\n",
    "        \"temperature\": 0.7, \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863f1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f4d4c132a50>\n",
       "üöÖ Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OllamaChatGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (list[float])\n",
       "  - retriever.documents -> prompt_builder.example_pair (list[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "third_pipeline = Pipeline()\n",
    "third_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "third_pipeline.add_component(\"retriever\", retriever)\n",
    "third_pipeline.add_component(\"prompt_builder\", Third_prompt_template)\n",
    "third_pipeline.add_component(\"llm\", third_chat_generator)\n",
    "\n",
    "third_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "third_pipeline.connect(\"retriever.documents\", \"prompt_builder.example_pair\")\n",
    "third_pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated Annotated Description:\n",
      "\n",
      "Here is the generated annotated description:\n",
      "\n",
      "The process begins when <bpmn:startEvent>Passenger Arrives at Destination</bpmn:startEvent>. The next step is to have the <bpmn:task>Passenger enters terminal</bpmn:task>, which has an outgoing flow to the <bpmn:task>Passenger goes to the mashine</bpmn:task>. This task's output flows into the <bpmn:task>Passenger gets his luggage</bpmn:task> (not present in this BPMN model, but added for context).\n",
      "\n",
      "After getting the luggage, the passenger needs to decide whether they want to check-in online or not. The decision is made at the <bpmn:exclusiveGateway>Do you want to check-in online?</bpmn:exclusiveGateway>. If they choose to check-in online, the flow goes to the <bpmn:task>Passenger checks in online</bpmn:task>, and if not, it flows into the <bpmn:task>Passenger checks in at the counter</bpmn:task>.\n",
      "\n",
      "If the passenger chooses to check-in at the counter, they need to go through security, which is represented by the <bpmn:task>Security Check</bpmn:task> (not present in this BPMN model).\n",
      "\n",
      "After checking in and going through security (if necessary), the passenger can proceed to their gate. However, if they chose to check-in online, a new task is added before proceeding to the gate: <bpmn:task>Get boarding pass</bpmn:task>. This task's output flows into the final step of the process.\n",
      "\n",
      "The last step in the process is for the passenger to arrive at their gate and board the plane. However, this is not a task but an end event, so it is represented by <bpmn:endEvent>Arrival at Gate</bpmn:endEvent>.\n"
     ]
    }
   ],
   "source": [
    "NEW_BPMN_FILE = \"passenger_check_in_machine.bpmn\"  # \n",
    "with open(NEW_BPMN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    new_bpmn_content = f.read().strip()\n",
    "\n",
    "result = third_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": new_bpmn_content},\n",
    "    \"prompt_builder\": {\"new_bpmn\": new_bpmn_content}\n",
    "})\n",
    "annotated = result[\"llm\"][\"replies\"][0].text.strip()\n",
    "print(\"\\n‚úÖ Generated Annotated Description:\\n\")\n",
    "print(annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e8e95",
   "metadata": {},
   "source": [
    "Passenger_check_in_machine.bpmn\n",
    "The model were able to annotate  0 events out of 2 ,  4 tasks out of 7  and  0 gateways out of 2\n",
    "Precision = 0.4 Recall = 0.36 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae6338",
   "metadata": {},
   "source": [
    "<font size=\"6\">Exercise 3 Running this pipeline for 2 different BPMN models.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 37.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated Annotated Description:\n",
      "\n",
      "The process begins with the <bpmn:startEvent>Start Event</bpmn:startEvent>. The next step is <bpmn:task>Passenger enters terminal</bpmn:task>, where the passenger arrives at the terminal. Following this, the passenger proceeds to <bpmn:task>Passenger goes to the counter</bpmn:task>. The process then leads to <bpmn:task>Passenger has to identify</bpmn:task>, where the passenger identifies themselves. After that, the passenger attends <bpmn:task>Exact Task Name (Activity_0y72hjp)</bpmn:task>.\n",
      "\n",
      "The process then reaches an exclusive gateway at <bpmn:exclusiveGateway>Does the passenger have luggage?</bpmn:exclusiveGateway>. If the answer is yes, the process leads to <bpmn:task>Luggage Handling</bpmn:task>, which is not present in this model but would be if it were included. However, according to the model, if the answer is no, or we assume that is what \"Yes\" means here as there's only two options and they are not specified directly (it could also mean no), then the process continues with <bpmn:task>Passenger proceeds</bpmn:task>, which seems to be Activity_09u2bux.\n",
      "\n",
      "After this point, the passenger attends <bpmn:task>Activity_129gov3</bpmn:task>. The final step in the process is the <bpmn:endEvent>End Event</bpmn:endEvent>.\n"
     ]
    }
   ],
   "source": [
    "NEW_BPMN_FILE_2 = \"passenger_check_in_counter.bpmn\"  # \n",
    "with open(NEW_BPMN_FILE_2, \"r\", encoding=\"utf-8\") as f:\n",
    "    new_bpmn_content = f.read().strip()\n",
    "\n",
    "result = third_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": new_bpmn_content},\n",
    "    \"prompt_builder\": {\"new_bpmn\": new_bpmn_content}\n",
    "})\n",
    "\n",
    "annotated = result[\"llm\"][\"replies\"][0].text.strip()\n",
    "print(\"\\n‚úÖ Generated Annotated Description:\\n\")\n",
    "print(annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5befa5",
   "metadata": {},
   "source": [
    "Passenger_check_in_counter \n",
    "The model were able to annotate 2 events out of 2 ,¬†  6 tasks out of 7 and 1 gateways out of 2 \n",
    "Precision = 0.9  Recall =0.81 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e550a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "doc_embedder.warm_up()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984acb5",
   "metadata": {},
   "source": [
    "<font size=\"6\">Exercise 3 Replacing the BPMN-text pairs in the document store with BPMN-annotated-text pairs already containing tags</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cac71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded and embedded 4 documents into the document store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_paths = [\n",
    "    \"Passenger ArrivalAnotate.txt\",\n",
    "    \"Passenger SecurityAnotate.txt\",\n",
    "    \"Excess BaggageAnotate.txt\",\n",
    "    \"Delayed BaggageAnotate.txt\"\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().strip()\n",
    "      \n",
    "        doc = Document(content=content, meta={\"source\": file_path})\n",
    "        docs.append(doc)\n",
    "       \n",
    "embedded_docs = doc_embedder.run(docs)\n",
    "\n",
    "document_store.write_documents(embedded_docs[\"documents\"])\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded and embedded {len(docs)} documents into the document store.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636380d",
   "metadata": {},
   "source": [
    " <font size=\"6\">Exercise 3 rerunning the pipeline</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb47cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 27.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated Annotated Description:\n",
      "\n",
      "Here is the generated annotated description:\n",
      "\n",
      "The process begins with <bpmn:startEvent>Passenger Arrives at Terminal</bpmn:startEvent>.\n",
      "\n",
      "Next, the passenger <bpmn:task>Passenger enters terminal</bpmn:task>. \n",
      "\n",
      "Then, the passenger goes to the machine and performs an action in <bpmn:task>Activity_0h3ea40</bpmn:task>. After that, they go through a gateway where they decide whether or not they have a ticket. The gateway is labeled <bpmn:exclusiveGateway>Do you have a ticket?</bpmn:exclusiveGateway>.\n",
      "\n",
      "If the passenger does have a ticket, then they proceed to select their seat in <bpmn:task>Activity_0y72hjp</bmn:task>. \n",
      "\n",
      "However, if they do not have a ticket, they are directed to buy one at <bpmn:task>Activity_074g467</bpmn:task>.\n",
      "\n",
      "After either of these tasks is completed, the passenger proceeds to retrieve their boarding pass in <bpmn:task>Activity_09u2bux</bmn:task>. \n",
      "\n",
      "Finally, they reach their destination and the process ends with <bpmn:endEvent>End of Journey</bpmn:endEvent>.\n"
     ]
    }
   ],
   "source": [
    "NEW_BPMN_FILE = \"passenger_check_in_machine.bpmn\"  # \n",
    "with open(NEW_BPMN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    new_bpmn_content = f.read().strip()\n",
    "\n",
    "result = third_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": new_bpmn_content},\n",
    "    \"prompt_builder\": {\"new_bpmn\": new_bpmn_content}\n",
    "})\n",
    "annotated = result[\"llm\"][\"replies\"][0].text.strip()\n",
    "print(\"\\n‚úÖ Generated Annotated Description:\\n\")\n",
    "print(annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e1968",
   "metadata": {},
   "source": [
    "Passenger_check_in_machine\n",
    "The model were able to annotate  0 events out of 2 ,  5 tasks out of 7  and  0 gateways out of 2\n",
    "Precision =0.62  Recall = 0.45  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 38.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated Annotated Description:\n",
      "\n",
      "Here is the generated annotated description of the BPMN model:\n",
      "\n",
      "The process begins with a <bpmn:startEvent>Passenger arrives at the terminal</bpmn:startEvent>. \n",
      "\n",
      "Next, the passenger enters the terminal in <bpmn:task>Passenger enters terminal</bpmn:task>, which leads to <bpmn:task>Passenger goes to the counter</bpmn:task>. \n",
      "\n",
      "At this point, the passenger checks if they have a boarding pass in <bpmn:exclusiveGateway>Do you have a boarding pass?</bpmn:exclusiveGateway>. If yes, they proceed to <bpmn:task>Check-in</bpmn:task>, and then go through security in <bpmn:task>Security Check</bpmn:task>.\n",
      "\n",
      "However, if the passenger does not have a boarding pass, they need to purchase one at <bpmn:task>Purchase Boarding Pass</bpmn:task>. After purchasing their boarding pass, they proceed to check-in in <bpmn:task>Check-in</bpmn:task>, and then go through security in <bpmn:task>Security Check</bpmn:task>.\n",
      "\n",
      "After clearing security, the passenger proceeds to the gate in <bpmn:exclusiveGateway>Is your flight delayed?</bpmn:exclusiveGateway>. If yes, they wait for their flight to be called at <bpmn:task>Wait for Flight to be Called</bpmn:task>. \n",
      "\n",
      "However, if their flight is on time, they board the plane in <bpmn:task>Board Plane</bpmn:task>, and then disembark when it reaches its destination in <bpmn:endEvent>Arrival at Destination</bpmn:endEvent>.\n"
     ]
    }
   ],
   "source": [
    "NEW_BPMN_FILE_2 = \"passenger_check_in_counter.bpmn\"  # \n",
    "with open(NEW_BPMN_FILE_2, \"r\", encoding=\"utf-8\") as f:\n",
    "    new_bpmn_content = f.read().strip()\n",
    "\n",
    "result = third_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": new_bpmn_content},\n",
    "    \"prompt_builder\": {\"new_bpmn\": new_bpmn_content}\n",
    "})\n",
    "annotated = result[\"llm\"][\"replies\"][0].text.strip()\n",
    "print(\"\\n‚úÖ Generated Annotated Description:\\n\")\n",
    "print(annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9dc9d",
   "metadata": {},
   "source": [
    "Passenger_check_in_counter \n",
    "The model were able to annotate 0 events out of 2,  3 tasks out of 7  and  0 gateways out of 2  \n",
    "Precision = 0.3  Recall = 0.27"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
