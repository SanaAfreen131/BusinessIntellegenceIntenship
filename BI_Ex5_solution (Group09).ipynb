{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437800db",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; \n",
    "            border: 2px solid #4CAF50;   \n",
    "            background-color: #DFF2BF;       \n",
    "            color: #2F2F2F;                  /* Dark text */\n",
    "            padding: 20px; \n",
    "            border-radius: 10px; \n",
    "            width: 95%; \n",
    "            margin: auto;\">\n",
    "\n",
    "<h2>-- BI Assignment Exercise 05 ---</h2>\n",
    "<h3>Group 09</h3>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa1443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: haystack-ai==2.19 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (2.19.0)\n",
      "Requirement already satisfied: docstring-parser in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (0.17.0)\n",
      "Requirement already satisfied: filetype in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (1.2.0)\n",
      "Requirement already satisfied: haystack-experimental in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (0.14.3)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (4.23.0)\n",
      "Requirement already satisfied: lazy-imports in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (10.5.0)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (3.4.2)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.13/site-packages (from haystack-ai==2.19) (2.2.6)\n",
      "Requirement already satisfied: openai>=1.99.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (2.8.1)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (7.0.1)\n",
      "Requirement already satisfied: pydantic in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (2.12.4)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python3.13/site-packages (from haystack-ai==2.19) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (9.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.13/site-packages (from haystack-ai==2.19) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai==2.19) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai==2.19) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai==2.19) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai==2.19) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->haystack-ai==2.19) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->haystack-ai==2.19) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->haystack-ai==2.19) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests->haystack-ai==2.19) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.13/site-packages (from requests->haystack-ai==2.19) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests->haystack-ai==2.19) (2.3.0)\n",
      "Requirement already satisfied: rich in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-experimental->haystack-ai==2.19) (14.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->haystack-ai==2.19) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/lib64/python3.13/site-packages (from jsonschema->haystack-ai==2.19) (0.25.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai==2.19) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai==2.19) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.99.2->haystack-ai==2.19) (0.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai==2.19) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai==2.19) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->haystack-experimental->haystack-ai==2.19) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ollama-haystack in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (5.3.0)\n",
      "Requirement already satisfied: haystack-ai>=2.19.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from ollama-haystack) (2.19.0)\n",
      "Requirement already satisfied: ollama>=0.5.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from ollama-haystack) (0.6.1)\n",
      "Requirement already satisfied: pydantic in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from ollama-haystack) (2.12.4)\n",
      "Requirement already satisfied: docstring-parser in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (0.17.0)\n",
      "Requirement already satisfied: filetype in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (1.2.0)\n",
      "Requirement already satisfied: haystack-experimental in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (0.14.3)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (4.23.0)\n",
      "Requirement already satisfied: lazy-imports in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (10.5.0)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (3.4.2)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.2.6)\n",
      "Requirement already satisfied: openai>=1.99.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.8.1)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (7.0.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (9.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-ai>=2.19.0->ollama-haystack) (4.15.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /usr/lib/python3.13/site-packages (from ollama>=0.5.0->ollama-haystack) (0.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->ollama-haystack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->ollama-haystack) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from pydantic->ollama-haystack) (0.4.2)\n",
      "Requirement already satisfied: anyio in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (4.8.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/lib/python3.13/site-packages (from httpx>=0.27->ollama>=0.5.0->ollama-haystack) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama>=0.5.0->ollama-haystack) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai>=2.19.0->ollama-haystack) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from openai>=1.99.2->haystack-ai>=2.19.0->ollama-haystack) (0.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai>=2.19.0->ollama-haystack) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from posthog!=3.12.0->haystack-ai>=2.19.0->ollama-haystack) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests->haystack-ai>=2.19.0->ollama-haystack) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests->haystack-ai>=2.19.0->ollama-haystack) (2.3.0)\n",
      "Requirement already satisfied: rich in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (14.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->haystack-ai>=2.19.0->ollama-haystack) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/lib/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/lib64/python3.13/site-packages (from jsonschema->haystack-ai>=2.19.0->ollama-haystack) (0.25.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3.13/site-packages (from rich->haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/users3/asdf/s7432340/.local/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->haystack-experimental->haystack-ai>=2.19.0->ollama-haystack) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install haystack-ai==2.19\n",
    "! pip install ollama-haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277de5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack_integrations.components.generators.ollama import  OllamaChatGenerator\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from typing import List, Dict, Any\n",
    "import xml.etree.ElementTree as ET\n",
    "import pydantic\n",
    "from pydantic import BaseModel\n",
    "from haystack import Pipeline\n",
    "from haystack import Document\n",
    "from haystack import component\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018390a",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> -- Exercise 01 --</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a006c",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-1 (a)</h2>\n",
    "\n",
    "### Write Python Code to automatically extract all element names from a BPMN file. (1 Point) \n",
    "\n",
    "‚Ä¢ Input: .bpmn file <br>\n",
    "‚Ä¢ Output: Names of Tasks(, Events and Gateways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301bc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_description_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "def extract_bpmn_elements_by_type(bpmn_file_path: str) -> Dict[str, List[str]]:\n",
    "    ns = {'bpmn': 'http://www.omg.org/spec/BPMN/20100524/MODEL'}\n",
    "    tree = ET.parse(bpmn_file_path)\n",
    "    root = tree.getroot()\n",
    "    tags = ['task', 'startEvent', 'endEvent', 'exclusiveGateway', 'parallelGateway']\n",
    "\n",
    "    result = {}\n",
    "    for tag in tags:\n",
    "        names = [elem.get('name', '').strip() for elem in root.findall(f'.//bpmn:{tag}', ns) if elem.get('name')]\n",
    "        result[tag] = names\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712855af",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-1 (b)</h2>\n",
    "\n",
    "### Choose one of the methods from last exercise sheet (Structured Outputs, Text Annotation or generating an annotated text) to get a list of elements from a BPMN description. (1 Point) \n",
    "\n",
    "‚Ä¢ Input: Descriptive Text of a BPMN-model (and the corresponding .bpmn) <br>\n",
    "‚Ä¢ Output: Names of Tasks, Events and Gateways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d02156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task(BaseModel):\n",
    "    name: str\n",
    "\n",
    "class Event(BaseModel):\n",
    "    name: str\n",
    "\n",
    "class Gateway(BaseModel):\n",
    "    name: str\n",
    "\n",
    "class ElementsData(BaseModel):\n",
    "    tasks: List[Task] = []\n",
    "    events: List[Event] = []\n",
    "    gateways: List[Gateway] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96e1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Output Validator ---\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    @component.output_types(\n",
    "        valid_replies=List[ChatMessage],\n",
    "        invalid_replies=List[ChatMessage],\n",
    "        error_message=str\n",
    "    )\n",
    "    def run(self, replies: List[ChatMessage]):\n",
    "        self.iteration_counter += 1\n",
    "        try:\n",
    "            text = replies[0].text\n",
    "            parsed = json.loads(text)\n",
    "            self.pydantic_model.model_validate(parsed)\n",
    "            print(f\"\\033[92m‚úÖ Valid output at attempt {self.iteration_counter}\\033[0m\")\n",
    "            return {\"valid_replies\": replies}\n",
    "        except Exception as e:\n",
    "            print(f\"\\033[91m‚ùå Invalid output (attempt {self.iteration_counter}): {e}\\033[0m\")\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaf40cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class BPMNElementExtractor:\n",
    "    @component.output_types(bpmn_elements=List[str])\n",
    "    def run(self, bpmn_file_path: str):\n",
    "        elements_dict = extract_bpmn_elements_by_type(bpmn_file_path)\n",
    "        all_names = []\n",
    "        for key in ['task', 'startEvent', 'endEvent', 'exclusiveGateway', 'parallelGateway']:\n",
    "            all_names.extend(elements_dict.get(key, []))\n",
    "        return {\"bpmn_elements\": all_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9f8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class FlattenElements:\n",
    "    @component.output_types(flattened_elements=List[str])\n",
    "    def run(self, replies: List[ChatMessage]):\n",
    "        try:\n",
    "            text = replies[0].text\n",
    "            data = json.loads(text)\n",
    "            names = []\n",
    "            for item in data.get(\"tasks\", []):\n",
    "                if item.get(\"name\"):\n",
    "                    names.append(item[\"name\"].strip())\n",
    "            for item in data.get(\"events\", []):\n",
    "                if item.get(\"name\"):\n",
    "                    names.append(item[\"name\"].strip())\n",
    "            for item in data.get(\"gateways\", []):\n",
    "                if item.get(\"name\"):\n",
    "                    names.append(item[\"name\"].strip())\n",
    "            return {\"flattened_elements\": names}\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Flattening failed: {e}\")\n",
    "            return {\"flattened_elements\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf2380",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-1 (C)</h2>\n",
    "\n",
    "### Write a component, that matches the elements extracted from the BPMN and the text and automatically computes the precision and recall values. (2 Points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b7a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "class PrecisionRecallMatcher:\n",
    "    @component.output_types(precision=float, recall=float)\n",
    "    def run(self, bpmn_elements: List[str], extracted_elements: List[str]):\n",
    "        bpmn_set = set([e.lower().strip() for e in bpmn_elements if e])\n",
    "        extracted_set = set([e.lower().strip() for e in extracted_elements if e])\n",
    "        if not extracted_set or not bpmn_set:\n",
    "            return {\"precision\": 0.0, \"recall\": 0.0}\n",
    "        correct = len(bpmn_set & extracted_set)\n",
    "        precision = correct / len(extracted_set)\n",
    "        recall = correct / len(bpmn_set)\n",
    "        return {\"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ce9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_template = [ChatMessage.from_user(\"\"\"\n",
    "Extract ALL element names (Tasks, Start/End Events, Gateways) from the BPMN description below.\n",
    "\n",
    "{{bpmn_description}}\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "{\n",
    "  \"tasks\": [{\"name\": \"task name 1\"}, ...],\n",
    "  \"events\": [{\"name\": \"event name 1\"}, ...],\n",
    "  \"gateways\": [{\"name\": \"gateway name 1\"}, ...]\n",
    "}\n",
    "Rules:\n",
    "- Extract ONLY element NAMES as mentioned in the text.\n",
    "- Return valid JSON‚Äîno markdown, no explanation.\n",
    "{% if invalid_replies and error_message %}\n",
    "Previous output was invalid:\n",
    "{{invalid_replies}}\n",
    "Error: {{error_message}}\n",
    "Fix it and return valid JSON.\n",
    "{% endif %}\n",
    "\"\"\".strip())]\n",
    "\n",
    "prompt_builder = ChatPromptBuilder(template=prompt_template, required_variables=[\"bpmn_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dede63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_generator = OllamaChatGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=1800,\n",
    "    generation_kwargs={\"num_ctx\": 4096, \"temperature\": 0.3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0e1c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline(max_runs_per_component=3)\n",
    "\n",
    "pipeline.add_component(\"bpmn_extractor\", BPMNElementExtractor())\n",
    "pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipeline.add_component(\"llm\", chat_generator)\n",
    "pipeline.add_component(\"validator\", OutputValidator(pydantic_model=ElementsData))\n",
    "pipeline.add_component(\"flattener\", FlattenElements())\n",
    "pipeline.add_component(\"matcher\", PrecisionRecallMatcher())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8752742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fc89f635400>\n",
       "üöÖ Components\n",
       "  - bpmn_extractor: BPMNElementExtractor\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OllamaChatGenerator\n",
       "  - validator: OutputValidator\n",
       "  - flattener: FlattenElements\n",
       "  - matcher: PrecisionRecallMatcher\n",
       "üõ§Ô∏è Connections\n",
       "  - bpmn_extractor.bpmn_elements -> matcher.bpmn_elements (List[str])\n",
       "  - prompt_builder.prompt -> llm.messages (list[ChatMessage])\n",
       "  - llm.replies -> validator.replies (List[ChatMessage])\n",
       "  - validator.valid_replies -> flattener.replies (List[ChatMessage])\n",
       "  - flattener.flattened_elements -> matcher.extracted_elements (List[str])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.connect(\"bpmn_extractor.bpmn_elements\", \"matcher.bpmn_elements\")\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
    "pipeline.connect(\"llm.replies\", \"validator.replies\")\n",
    "pipeline.connect(\"validator.valid_replies\", \"flattener.replies\")\n",
    "pipeline.connect(\"flattener.flattened_elements\", \"matcher.extracted_elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243f2a3",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-1 (d)</h2>\n",
    "\n",
    "### Run a pipeline containing the elements from a)-c) for 3 different descriptive texts of BPMN models. (2 Points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80d4c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting evaluation: 3 BPMN models vs 3 corresponding descriptions\n",
      "\n",
      "--- Pair 1: EX1Delayed_Baggage.bpmn ‚Üî EX1Delayed_Baggage.txt ---\n",
      "\u001b[92m‚úÖ Valid output at attempt 1\u001b[0m\n",
      "\u001b[94müìä Result: Precision = 1.00, Recall = 1.00\u001b[0m\n",
      "\n",
      "--- Pair 2: EX1Passenger Security.bpmn ‚Üî EX1Passenger Security.txt ---\n",
      "\u001b[92m‚úÖ Valid output at attempt 2\u001b[0m\n",
      "\u001b[94müìä Result: Precision = 0.60, Recall = 0.33\u001b[0m\n",
      "\n",
      "--- Pair 3: EX1Passenger Arrival.bpmn ‚Üî EX1Passenger Arrival.txt ---\n",
      "\u001b[92m‚úÖ Valid output at attempt 3\u001b[0m\n",
      "\u001b[94müìä Result: Precision = 0.00, Recall = 0.00\u001b[0m\n",
      "\n",
      "‚úÖ Evaluation completed for all 3 model-description pairs.\n"
     ]
    }
   ],
   "source": [
    "# Define your 3 pairs: (bpmn_file, description_file)\n",
    "EVAL_PAIRS = [\n",
    "    (\"EX1Delayed_Baggage.bpmn\", \"EX1Delayed_Baggage.txt\"),\n",
    "    (\"EX1Passenger Security.bpmn\", \"EX1Passenger Security.txt\"),\n",
    "    (\"EX1Passenger Arrival.bpmn\", \"EX1Passenger Arrival.txt\"),\n",
    "]\n",
    "\n",
    "# Validate all files exist\n",
    "for bpmn_file, desc_file in EVAL_PAIRS:\n",
    "    if not os.path.exists(bpmn_file):\n",
    "        raise FileNotFoundError(f\"Missing BPMN file: {bpmn_file}\")\n",
    "    if not os.path.exists(desc_file):\n",
    "        raise FileNotFoundError(f\"Missing description file: {desc_file}\")\n",
    "\n",
    "print(\"üöÄ Starting evaluation: 3 BPMN models vs 3 corresponding descriptions\\n\")\n",
    "\n",
    "for i, (bpmn_file, desc_file) in enumerate(EVAL_PAIRS, 1):\n",
    "    print(f\"--- Pair {i}: {bpmn_file} ‚Üî {desc_file} ---\")\n",
    "    \n",
    "    # Read description text\n",
    "    description_text = read_description_file(desc_file)\n",
    "    \n",
    "    # Run pipeline with THIS BPMN and THIS description\n",
    "    result = pipeline.run({\n",
    "        \"bpmn_extractor\": {\"bpmn_file_path\": bpmn_file},\n",
    "        \"prompt_builder\": {\"bpmn_description\": description_text}\n",
    "    })\n",
    "    \n",
    "    precision = result[\"matcher\"][\"precision\"]\n",
    "    recall = result[\"matcher\"][\"recall\"]\n",
    "    \n",
    "    print(f\"\\033[94müìä Result: Precision = {precision:.2f}, Recall = {recall:.2f}\\033[0m\\n\")\n",
    "\n",
    "print(\"‚úÖ Evaluation completed for all 3 model-description pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243aeb9c",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">-- Exercise 02 --</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d183318",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-2 (a)</h2>\n",
    "\n",
    "### Create a pipeline for a RAG system, that receives a mistake of a given text and tries to remove the mistakes. It should contain following components: (6 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348b17cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load and parse the JSON rules\n",
    "file_path = \"correction_rules.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    rules = json.load(f)  #`rules` is a list of dictionaries\n",
    "\n",
    "# 2. Create one Document per rule\n",
    "docs = []\n",
    "for rule in rules:\n",
    "    doc = Document(\n",
    "        content=rule[\"instruction\"],          # The text to retrieve\n",
    "        meta={\n",
    "            \"rule_type\": rule[\"rule_type\"],\n",
    "            \"element_type\": rule[\"element_type\"],\n",
    "            \"error_pattern\": rule[\"error_pattern\"]\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "# 3. Embed and store documents\n",
    "document_store = InMemoryDocumentStore()\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "doc_embedder.warm_up()\n",
    "embedded_docs = doc_embedder.run(docs)\n",
    "\n",
    "# 4. Write embedded documents to store\n",
    "document_store.write_documents(embedded_docs[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb3d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@component\n",
    "class RuleRetriever:\n",
    "    def __init__(self, document_store: InMemoryDocumentStore, top_k: int = 1):\n",
    "        self.text_embedder = SentenceTransformersTextEmbedder(\n",
    "            model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        self.retriever = InMemoryEmbeddingRetriever(document_store, top_k=1)\n",
    "        self.text_embedder.warm_up()\n",
    "\n",
    "    @component.output_types(rules=list[Document])\n",
    "    def run(self, query: str):\n",
    "        embedding_result = self.text_embedder.run(query)\n",
    "        retrieved = self.retriever.run(embedding_result[\"embedding\"])\n",
    "        return {\"rules\": retrieved[\"documents\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb13b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_retriever = RuleRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436f8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = [\n",
    "    ChatMessage.from_system(\n",
    "        \"You are a BPMN correction expert. \"\n",
    "        \"Your task is to revise a textual description of a BPMN process based on specific feedback. \"\n",
    "        \"You must apply the feedback precisely and preserve all other correct parts of the description. \"\n",
    "        \"Only output the corrected description‚Äîno explanations, no markdown, no extra text.\"\n",
    "    ),\n",
    "    ChatMessage.from_user(\n",
    "        \"Process Input:\\n{{bpmn_and_description}}\\n\\n\"\n",
    "        \"Feedback/Instruction:\\n{{feedback_instruction}}\\n\\n\"\n",
    "        \"Corrected Description:\"\n",
    "    )\n",
    "]\n",
    "\n",
    "chat_prompt_builder = ChatPromptBuilder(\n",
    "    template=chat_template,\n",
    "    required_variables=[\"bpmn_and_description\", \"feedback_instruction\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6716ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the Ollama chat generator\n",
    "chat_generator2 = OllamaChatGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=30*60,  # 30 minutes\n",
    "    generation_kwargs={\n",
    "        \"num_ctx\": 4096,\n",
    "        \"temperature\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e05e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f061e768830>\n",
       "üöÖ Components\n",
       "  - retriever: RuleRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - generator: OllamaChatGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - retriever.rules -> prompt_builder.feedback_instruction (list[Document])\n",
       "  - prompt_builder.prompt -> generator.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build pipeline\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"retriever\", custom_retriever)\n",
    "pipe.add_component(\"prompt_builder\", chat_prompt_builder)\n",
    "pipe.add_component(\"generator\", chat_generator2)\n",
    "\n",
    "pipe.connect(\"retriever.rules\", \"prompt_builder.feedback_instruction\")\n",
    "pipe.connect(\"prompt_builder.prompt\", \"generator.messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61b4a8",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-2 (b)</h2>\n",
    "\n",
    "### Run this pipeline for 3 different BPMN-text pairs where the text contains errors like missing tasks. Verify the results by checking if the error was fixed correctly, and if new errors were added to the texts. Present the results in your presentation. (3 Points)\n",
    "\n",
    "‚Ä¢ Input: A descriptive text with the corresponding .bpmn file and a feedback list. <br>\n",
    "‚Ä¢ Output: A descriptive text where the mistake has hopefully been corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c9eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 49.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Output 1 ---\n",
      "Process Input:\n",
      "Delayed Baggage\n",
      "\n",
      "Start Event: The process starts when the passenger arrives at the destination airport without their baggage.\n",
      "\n",
      "Baggage service office receives report: The baggage service office receives the delayed baggage report from the passenger.\n",
      "\n",
      "Initiate baggage tracing: The baggage service office initiates the baggage tracing process.\n",
      "\n",
      "Trace baggage across airlines: The baggage logistics system searches for the missing baggage across different airlines.\n",
      "\n",
      "Exclusive Gateway ‚Äì Is baggage located within 24 hours?\n",
      "A decision is made to check whether the baggage is found within 24 hours.\n",
      "\n",
      "Yes ‚Äì Proceed to delivery:\n",
      "If the baggage is located within 24 hours, the process proceeds toward delivery arrangements.\n",
      "\n",
      "No ‚Äì Continue tracking:\n",
      "If the baggage is not located within 24 hours, baggage tracing continues.\n",
      "\n",
      "Activate interim support: The task \"activate interim support\" is missing in the description of the process model. This task activates interim support (e.g., compensation or essential items) while tracing continues.\n",
      "\n",
      "Passenger receives interim support: The passenger receives interim support while waiting for the baggage.\n",
      "\n",
      "Merge Gateway:\n",
      "The tracing and interim support paths are synchronized and merged.\n",
      "\n",
      "Proceed to delivery:\n",
      "Once the baggage is found, the process proceeds to deliver the baggage to the passenger.\n",
      "\n",
      "Deliver baggage to passenger: The task \"Deliver Baggage to Passenger\" is missing in the description of the process model. This task delivers the baggage to the passenger.\n",
      "\n",
      "Exclusive Gateway ‚Äì Is baggage found within 21 days?\n",
      "A decision is made to determine whether the baggage was found within 21 days.\n",
      "\n",
      "Yes ‚Äì Close case:\n",
      "If the baggage is found within 21 days, the baggage service office closes the case.\n",
      "\n",
      "No ‚Äì Presumed lost:\n",
      "If the baggage is not found within 21 days, the baggage is classified as presumed lost.\n",
      "\n",
      "Merge Gateway:\n",
      "Both outcomes (case closed or presumed lost) are merged into a single path.\n",
      "\n",
      "Passenger confirms Delivery: The task \"Passenger confirms Delivery\" is missing in the description of the process model. This task allows the passenger to confirm that the delivery was successful.\n",
      "\n",
      "End Event: The process ends when the passenger confirms that the delivery was successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 50.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Output 2 ---\n",
      "Process Input:\n",
      "Exces_bagage\n",
      "\n",
      "Start Event: The process begins when flight check-in starts.\n",
      "\n",
      "Flight check-in begins: The passenger enters the check-in phase for the flight.\n",
      "\n",
      "Assess flight occupancy: The system evaluates various capacity-related indicators and operational \n",
      "factors to determine an appropriate occupancy-related condition without explicitly \n",
      "specifying thresholds or decision criteria.\n",
      "\n",
      "Exclusive Gateway ‚Äì Is occupancy high?\n",
      "A decision is made to determine whether the flight occupancy is high.\n",
      "\n",
      "Yes ‚Äì Enhance baggage control:\n",
      "If occupancy is high, enhanced baggage control measures are applied.\n",
      "\n",
      "Notify passengers of strict carry-on enforcement:\n",
      "Passengers are informed that stricter carry-on baggage rules will be enforced.\n",
      "\n",
      "No ‚Äì Apply standard carry-on procedures:\n",
      "If occupancy is not high, standard carry-on baggage procedures are applied.\n",
      "\n",
      "Passenger receives notification:\n",
      "The passenger receives the notification about the carry-on baggage policy.\n",
      "\n",
      "Passenger arrives at the gate:\n",
      "The passenger arrives at the boarding gate.\n",
      "\n",
      "Gate-level carry-on verification:\n",
      "Gate staff verify the passenger‚Äôs carry-on baggage at the gate.\n",
      "\n",
      "Exclusive Gateway ‚Äì Carry-on compliant?\n",
      "A decision is made to check whether the passenger‚Äôs carry-on baggage complies with the rules.\n",
      "\n",
      "Yes ‚Äì Allow passenger for boarding:\n",
      "If the carry-on baggage is compliant, the passenger is allowed to board the aircraft.\n",
      "\n",
      "Passenger ready for boarding:\n",
      "The passenger is prepared and cleared for boarding.\n",
      "\n",
      "No ‚Äì Proceed to overflow handling:\n",
      "If the carry-on baggage is not compliant, it is sent for overflow handling.\n",
      "\n",
      "Tag item and load into aircraft hold:\n",
      "The excess carry-on item is tagged and loaded into the aircraft‚Äôs cargo hold.\n",
      "\n",
      "Merge Gateway:\n",
      "Both compliant and non-compliant baggage paths converge back into the main flow.\n",
      "\n",
      "Passenger boards flight on time:\n",
      "The passenger boards the flight as scheduled.\n",
      "\n",
      "End Event:\n",
      "The process ends once the passenger has boarded the flight on time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Output 3 ---\n",
      "Process Input:\n",
      "Passenger Arrival\n",
      "\n",
      "Start Event: The process begins when the passenger arrives at the terminal.\n",
      "\n",
      "Passenger arrives at terminal: The passenger enters the airport terminal.\n",
      "\n",
      "Yes ‚Äì Skip passport control:\n",
      "If the passenger arrives from the Schengen area, passport control is skipped.\n",
      "\n",
      "No ‚Äì Passenger goes to passport control:\n",
      "If the passenger arrives from outside the Schengen area, the passenger proceeds to passport control.\n",
      "\n",
      "Passenger shows passport:\n",
      "The passenger presents their passport for inspection.\n",
      "\n",
      "Exclusive Gateway: Arrival from Schengen area\n",
      "A decision is made to check whether the passenger has arrived from the Schengen area.\n",
      "\n",
      "Yes ‚Äì Skip passport control:\n",
      "If the passenger arrives from the Schengen area, passport control is skipped.\n",
      "\n",
      "No ‚Äì Passenger goes to passport control:\n",
      "If the passenger arrives from outside the Schengen area, the passenger proceeds to passport control.\n",
      "\n",
      "Passenger goes to passport control:\n",
      "The passenger proceeds to passport control.\n",
      "\n",
      "Exclusive Gateway: Passenger has Baggage?\n",
      "A decision is made to check whether the passenger has checked baggage.\n",
      "\n",
      "Yes ‚Äì Passenger takes baggage:\n",
      "If the passenger has baggage, they collect their baggage from the baggage claim.\n",
      "\n",
      "No ‚Äì Skip baggage collection:\n",
      "If the passenger has no baggage, this step is skipped.\n",
      "\n",
      "Merge Gateway:\n",
      "Both baggage-related paths merge into a single flow.\n",
      "\n",
      "Exclusive Gateway: Goods to declare?\n",
      "A decision is made to determine whether the passenger has goods to declare at customs.\n",
      "\n",
      "Yes ‚Äì Passenger goes to customs:\n",
      "If the passenger has goods to declare, they proceed to customs.\n",
      "\n",
      "Passenger declares goods at customs:\n",
      "The passenger declares the goods to customs authorities.\n",
      "\n",
      "No ‚Äì Skip customs declaration:\n",
      "If the passenger has no goods to declare, customs is skipped.\n",
      "\n",
      "Merge Gateway:\n",
      "Both customs-related paths merge back into a single process flow.\n",
      "\n",
      "Passenger leaves airport:\n",
      "The passenger exits the airport.\n",
      "\n",
      "End Event:\n",
      "The process ends when the passenger leaves the airport.\n"
     ]
    }
   ],
   "source": [
    "# Read combined BPMN+description from a single file\n",
    "def read_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Provide your 3 files and generic feedback messages (no element names needed)\n",
    "test_inputs = [\n",
    "    (\"Delayed BaggagePair.txt\", \"A task is missing in the description of the process model.\"),\n",
    "    (\"Exces_bagagePair.txt\", \"A task is hallucinated in the description of the process model.\"),\n",
    "    (\"Passenger ArrivalPair.txt\", \"A gateway is missing in the description of the process model.\")\n",
    "]\n",
    "\n",
    "# Run pipeline\n",
    "for i, (filename, feedback) in enumerate(test_inputs, 1):\n",
    "    content = read_file(filename)\n",
    "    output = pipe.run({\n",
    "        \"retriever\": {\"query\": feedback},\n",
    "        \"prompt_builder\": {\"bpmn_and_description\": content}\n",
    "    })\n",
    "    corrected = output[\"generator\"][\"replies\"][0].text.strip()\n",
    "    print(f\"\\n--- Output {i} ---\\n{corrected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39e1cc",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> -- Exercise 03 --</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebaab7a",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-3 (a)</h2>\n",
    "\n",
    "### Create a Pipeline that takes a descriptive text of a BPMN model as its input and evaluates its readability by instructing an LLM to give the text a score. (2 Points)\n",
    "\n",
    "‚Ä¢ Input: Descriptive Text of a BPMN-model<br>\n",
    "‚Ä¢ Output: A score (maybe 0‚Äì5, or 0‚Äì10, be creative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae821bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt = PromptBuilder(\n",
    "    template=\"\"\"\n",
    "You are an experienced business analyst who reviews process documentation. \n",
    "Please evaluate the following description of a BPMN model for its readability. \n",
    "Readability means how clear, easy to understand, and well-structured the text is for someone reading it for the first time.\n",
    "\n",
    "Score it on a scale from 0 to 10, where:\n",
    "- 0 = completely unclear, confusing, or unreadable\n",
    "- 5 = moderately clear but has issues\n",
    "- 10 = perfectly clear, fluent, and easy to follow\n",
    "\n",
    "Only return the numeric score (e.g., '8' or '3.5'). Do not include any other text.\n",
    "\n",
    "Description:\n",
    "{{bpmn_description}}\n",
    "\"\"\",\n",
    "    required_variables=[\"bpmn_description\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aca6ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator3 = OllamaGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=30*60,\n",
    "    generation_kwargs={\n",
    "        \"num_ctx\": 4096,\n",
    "        \"temperature\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3289d038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f05dcfeec10>\n",
       "üöÖ Components\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OllamaGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Build Pipeline ---\n",
    "pipeline_s = Pipeline()\n",
    "pipeline_s.add_component(\"prompt_builder\", prompt)\n",
    "pipeline_s.add_component(\"llm\", generator3)\n",
    "pipeline_s.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a26a1",
   "metadata": {},
   "source": [
    " <h2 style=\"text-align: center;\">Ex-3 (b)</h2>\n",
    "\n",
    "### Run the pipeline using 3 different BPMN models from past exercises. For each, evaluate a generated descriptive text and a descriptive text written by yourself (ground truth) and compare the scoring results. Present the scores in your presentation. (3 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1299c359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Processing: ppassenger_check_in_counter.txt]\n",
      "Text preview: Passenger_check_in_counter\n",
      "\n",
      "The process a passenger follows at an airport termin...\n",
      "Readability Score: 8\n",
      "\n",
      "[Processing: ppassenger_check_in_machine.txt]\n",
      "Text preview: Passenger_check_in_machine\n",
      "\n",
      "A self-service airport check-in process that a passe...\n",
      "Readability Score: 7.5\n",
      "\n",
      "[Processing: pbaggage_departure.txt]\n",
      "Text preview: Baggage_departure\n",
      "\n",
      "Airport baggage handling and security screening from the mome...\n",
      "Readability Score: 9\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF READABILITY SCORES\n",
      "============================================================\n",
      "ppassenger_check_in_counter.txt ‚Üí Score: 8.0\n",
      "ppassenger_check_in_machine.txt ‚Üí Score: 7.5\n",
      "pbaggage_departure.txt ‚Üí Score: 9.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of text files \n",
    "text_files = [\"ppassenger_check_in_counter.txt\", \"ppassenger_check_in_machine.txt\", \"pbaggage_departure.txt\"]\n",
    "\n",
    "# Run pipeline on each file \n",
    "results = []\n",
    "\n",
    "for filename in text_files:\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    # Read the description from file\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        description = f.read().strip()\n",
    "\n",
    "    if not description:\n",
    "        print(f\"‚ö†Ô∏è Empty file: {filename}\")\n",
    "        continue\n",
    "    print(f\"\\n[Processing: {filename}]\")\n",
    "    print(f\"Text preview: {description[:80]}{'...' if len(description) > 80 else ''}\")\n",
    "\n",
    "    # Run pipeline\n",
    "    output = pipeline_s.run({\n",
    "        \"prompt_builder\": {\"bpmn_description\": description}\n",
    "    })\n",
    "\n",
    "    raw_score = output[\"llm\"][\"replies\"][0].strip()\n",
    "    print(f\"Readability Score: {raw_score}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"file\": filename,\n",
    "        \"description\": description,\n",
    "        \"score\": raw_score\n",
    "    })\n",
    "# Summary Table \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF READABILITY SCORES\")\n",
    "print(\"=\"*60)\n",
    "for res in results:\n",
    "    score = res['score']\n",
    "    filename = res['file']\n",
    "    # Try to clean/convert score\n",
    "    try:\n",
    "        score_val = float(score)\n",
    "        score_display = f\"{score_val:.1f}\"\n",
    "    except ValueError:\n",
    "        score_display = f\"'{score}'\"\n",
    "    print(f\"{filename:<15} ‚Üí Score: {score_display}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19216262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Processing: LPassenger_check_in_counter.txt]\n",
      "Text preview: Passenger_check_in_counter\n",
      "\n",
      "The process starts with a \"Passenger enters terminal...\n",
      "Readability Score: 8\n",
      "\n",
      "[Processing: Lpassenger_check_in_machine.txt]\n",
      "Text preview: Passenger_check_in_machine\n",
      "\n",
      "The process starts with a **StartEvent**, which trig...\n",
      "Readability Score: 8\n",
      "\n",
      "[Processing: Lbaggage_departure.txt]\n",
      "Text preview: Baggage_departure\n",
      "\n",
      "**Process Elements**\n",
      "* `Process_0gjrx3e`: This is the main pr...\n",
      "Readability Score: 7\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF READABILITY SCORES\n",
      "============================================================\n",
      "LPassenger_check_in_counter.txt ‚Üí Score: 8.0\n",
      "Lpassenger_check_in_machine.txt ‚Üí Score: 8.0\n",
      "Lbaggage_departure.txt ‚Üí Score: 7.0\n"
     ]
    }
   ],
   "source": [
    "# List of text files\n",
    "text_files = [\"LPassenger_check_in_counter.txt\", \"Lpassenger_check_in_machine.txt\", \"Lbaggage_departure.txt\"]\n",
    "\n",
    "# Run pipeline on each file\n",
    "results = []\n",
    "\n",
    "for filename in text_files:\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    # Read the description from file\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        description = f.read().strip()\n",
    "\n",
    "    if not description:\n",
    "        print(f\"‚ö†Ô∏è Empty file: {filename}\")\n",
    "        continue\n",
    "    print(f\"\\n[Processing: {filename}]\")\n",
    "    print(f\"Text preview: {description[:80]}{'...' if len(description) > 80 else ''}\")\n",
    "\n",
    "    # Run pipeline\n",
    "    output = pipeline_s.run({\n",
    "        \"prompt_builder\": {\"bpmn_description\": description}\n",
    "    })\n",
    "\n",
    "    raw_score = output[\"llm\"][\"replies\"][0].strip()\n",
    "    print(f\"Readability Score: {raw_score}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"file\": filename,\n",
    "        \"description\": description,\n",
    "        \"score\": raw_score\n",
    "    })\n",
    "# Summary Table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF READABILITY SCORES\")\n",
    "print(\"=\"*60)\n",
    "for res in results:\n",
    "    score = res['score']\n",
    "    filename = res['file']\n",
    "    # Try to clean/convert score\n",
    "    try:\n",
    "        score_val = float(score)\n",
    "        score_display = f\"{score_val:.1f}\"\n",
    "    except ValueError:\n",
    "        score_display = f\"'{score}'\"\n",
    "    print(f\"{filename:<15} ‚Üí Score: {score_display}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c2161",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Ex-3 (c)</h2>\n",
    "\n",
    "### Find another useful metric to evaluate the descriptive texts (apart from precision/recall and the metric used in exercise 3a.) and use an LLM to receive scoring results for this metric for the BPMN models used in exercise 3b. Present the scores in your presentation. (4* Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b773e41",
   "metadata": {},
   "source": [
    "Another useful metric completeness: Does it cover all key elements (start, end, gateways, tasks)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c189a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completeness_prompt_builder = PromptBuilder(\n",
    "    template=\"\"\"\n",
    "You are an experienced business analyst who reviews process documentation. \n",
    "Please evaluate the following description of a BPMN model for its completeness. \n",
    "Completeness means whether the description clearly mentions or implies all essential BPMN elements: \n",
    "- a clear starting point (e.g., \"the process begins when...\"), \n",
    "- one or more end points (e.g., \"the process ends with...\"), \n",
    "- all main tasks or activities, and \n",
    "- any decision points or gateways (e.g., \"if X, then do Y; otherwise, do Z\").\n",
    "\n",
    "Score it on a scale from 0 to 10, where:\n",
    "- 0 = missing most or all key elements (no start, no end, no decisions, vague steps)\n",
    "- 5 = includes some elements but omits important ones (e.g., has tasks but no start/end or decision logic)\n",
    "- 10 = fully covers start, end, tasks, and all relevant gateways clearly and unambiguously\n",
    "\n",
    "Only return the numeric score (e.g., '7' or '4.5'). Do not include any other text.\n",
    "\n",
    "Description:\n",
    "{{bpmn_description}}\n",
    "\"\"\",\n",
    "    required_variables=[\"bpmn_description\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f01d83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator4 = OllamaGenerator(\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434\",\n",
    "    timeout=30*60,\n",
    "    generation_kwargs={\n",
    "        \"num_ctx\": 4096,\n",
    "        \"temperature\": 0.9,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a51a5690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f05dd000190>\n",
       "üöÖ Components\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OllamaGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 3. Build Pipeline ---\n",
    "pipeline_c = Pipeline()\n",
    "pipeline_c.add_component(\"prompt_builder\", completeness_prompt_builder)\n",
    "pipeline_c.add_component(\"llm\", generator4)\n",
    "pipeline_c.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7538c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Processing: ppassenger_check_in_counter.txt]\n",
      "Text preview: Passenger_check_in_counter\n",
      "\n",
      "The process a passenger follows at an airport termin...\n",
      "Completeness score: 9\n",
      "\n",
      "[Processing: ppassenger_check_in_machine.txt]\n",
      "Text preview: Passenger_check_in_machine\n",
      "\n",
      "A self-service airport check-in process that a passe...\n",
      "Completeness score: 9\n",
      "\n",
      "[Processing: pbaggage_departure.txt]\n",
      "Text preview: Baggage_departure\n",
      "\n",
      "Airport baggage handling and security screening from the mome...\n",
      "Completeness score: 9.5\n",
      "\n",
      "============================================================\n",
      "Summary of Completeness score\n",
      "============================================================\n",
      "ppassenger_check_in_counter.txt ‚Üí Score: 9.0\n",
      "ppassenger_check_in_machine.txt ‚Üí Score: 9.0\n",
      "pbaggage_departure.txt ‚Üí Score: 9.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of text files \n",
    "text_files = [\"ppassenger_check_in_counter.txt\", \"ppassenger_check_in_machine.txt\", \"pbaggage_departure.txt\"]\n",
    "\n",
    "# Run pipeline on each file \n",
    "results = []\n",
    "\n",
    "for filename in text_files:\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    # Read the description from file\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        description = f.read().strip()\n",
    "\n",
    "    if not description:\n",
    "        print(f\"‚ö†Ô∏è Empty file: {filename}\")\n",
    "        continue\n",
    "    print(f\"\\n[Processing: {filename}]\")\n",
    "    print(f\"Text preview: {description[:80]}{'...' if len(description) > 80 else ''}\")\n",
    "\n",
    "    # Run pipeline\n",
    "    output = pipeline_c.run({\n",
    "        \"prompt_builder\": {\"bpmn_description\": description}\n",
    "    })\n",
    "\n",
    "    raw_score = output[\"llm\"][\"replies\"][0].strip()\n",
    "    print(f\"Completeness score: {raw_score}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"file\": filename,\n",
    "        \"description\": description,\n",
    "        \"score\": raw_score\n",
    "    })\n",
    "# Summary Table \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary of Completeness score\")\n",
    "print(\"=\"*60)\n",
    "for res in results:\n",
    "    score = res['score']\n",
    "    filename = res['file']\n",
    "    # Try to clean/convert score\n",
    "    try:\n",
    "        score_val = float(score)\n",
    "        score_display = f\"{score_val:.1f}\"\n",
    "    except ValueError:\n",
    "        score_display = f\"'{score}'\"\n",
    "    print(f\"{filename:<15} ‚Üí Score: {score_display}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a936204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Processing: LPassenger_check_in_counter.txt]\n",
      "Text preview: Passenger_check_in_counter\n",
      "\n",
      "The process starts with a \"Passenger enters terminal...\n",
      "Completeness Score: 9.5 \n",
      "\n",
      "(I corrected the score to 9.5 because the description is very detailed and clearly explains all main tasks, decision points, start and end points. However, it mentions \"two exclusive gateway labeled 'Decision'\", which could be seen as a minor ambiguity since gateways in BPMN should typically have unique names.)\n",
      "\n",
      "[Processing: Lpassenger_check_in_machine.txt]\n",
      "Text preview: Passenger_check_in_machine\n",
      "\n",
      "The process starts with a **StartEvent**, which trig...\n",
      "Completeness Score: 9\n",
      "\n",
      "[Processing: Lbaggage_departure.txt]\n",
      "Text preview: Baggage_departure\n",
      "\n",
      "**Process Elements**\n",
      "* `Process_0gjrx3e`: This is the main pr...\n",
      "Completeness Score: 8\n",
      "\n",
      "============================================================\n",
      "Summary of completeness Score\n",
      "============================================================\n",
      "LPassenger_check_in_counter.txt ‚Üí Score: '9.5 \n",
      "\n",
      "(I corrected the score to 9.5 because the description is very detailed and clearly explains all main tasks, decision points, start and end points. However, it mentions \"two exclusive gateway labeled 'Decision'\", which could be seen as a minor ambiguity since gateways in BPMN should typically have unique names.)'\n",
      "Lpassenger_check_in_machine.txt ‚Üí Score: 9.0\n",
      "Lbaggage_departure.txt ‚Üí Score: 8.0\n"
     ]
    }
   ],
   "source": [
    "# List of text files\n",
    "text_files = [\"LPassenger_check_in_counter.txt\", \"Lpassenger_check_in_machine.txt\", \"Lbaggage_departure.txt\"]\n",
    "\n",
    "# Run pipeline on each file\n",
    "results = []\n",
    "\n",
    "for filename in text_files:\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "    # Read the description from file\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        description = f.read().strip()\n",
    "\n",
    "    if not description:\n",
    "        print(f\"‚ö†Ô∏è Empty file: {filename}\")\n",
    "        continue\n",
    "    print(f\"\\n[Processing: {filename}]\")\n",
    "    print(f\"Text preview: {description[:80]}{'...' if len(description) > 80 else ''}\")\n",
    "\n",
    "    # Run pipeline\n",
    "    output = pipeline_c.run({\n",
    "        \"prompt_builder\": {\"bpmn_description\": description}\n",
    "    })\n",
    "\n",
    "    raw_score = output[\"llm\"][\"replies\"][0].strip()\n",
    "    print(f\"Completeness Score: {raw_score}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"file\": filename,\n",
    "        \"description\": description,\n",
    "        \"score\": raw_score\n",
    "    })\n",
    "# Summary Table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Summary of completeness Score\")\n",
    "print(\"=\"*60)\n",
    "for res in results:\n",
    "    score = res['score']\n",
    "    filename = res['file']\n",
    "    # Try to clean/convert score\n",
    "    try:\n",
    "        score_val = float(score)\n",
    "        score_display = f\"{score_val:.1f}\"\n",
    "    except ValueError:\n",
    "        score_display = f\"'{score}'\"\n",
    "    print(f\"{filename:<15} ‚Üí Score: {score_display}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
